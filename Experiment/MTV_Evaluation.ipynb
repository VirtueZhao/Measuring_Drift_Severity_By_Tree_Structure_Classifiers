{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation - Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "Similarity_Measurements = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
    "                          46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73,\n",
    "                          74, 75, 76]\n",
    "Distance_Measurements = [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 62]\n",
    "\n",
    "Files_Path = [\n",
    "    'MTV_Evaluation/Version_3/Reverse_Adult_Similarity.csv', 'MTV_Evaluation/Version_3/Reverse_Adult_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Bank_Similarity.csv', 'MTV_Evaluation/Version_3/Reverse_Bank_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Cardio_Similarity.csv', 'MTV_Evaluation/Version_3/Reverse_Cardio_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Chess_Similarity.csv', 'MTV_Evaluation/Version_3/Reverse_Chess_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Credit_Similarity.csv', 'MTV_Evaluation/Version_3/Reverse_Credit_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Diamonds_Similarity.csv', 'MTV_Evaluation/Version_3/Reverse_Diamonds_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Gamma_Similarity.csv', 'MTV_Evaluation/Version_3/Reverse_Gamma_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_PokerPart_Similarity.csv', 'MTV_Evaluation/Version_3/Reverse_PokerPart_Distance.csv',\n",
    "    \n",
    "    'MTV_Evaluation/Version_3/Feature_0_Adult_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_0_Adult_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Bank_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_0_Bank_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Cardio_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_0_Cardio_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Chess_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_0_Chess_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Credit_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_0_Credit_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Diamonds_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_0_Diamonds_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Gamma_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_0_Gamma_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_PokerPart_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_0_PokerPart_Distance.csv',\n",
    "    \n",
    "    'MTV_Evaluation/Version_3/Feature_1_Adult_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_1_Adult_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Bank_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_1_Bank_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Cardio_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_1_Cardio_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Chess_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_1_Chess_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Credit_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_1_Credit_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Diamonds_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_1_Diamonds_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Gamma_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_1_Gamma_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_PokerPart_Similarity.csv', 'MTV_Evaluation/Version_3/Feature_1_PokerPart_Distance.csv',\n",
    "]\n",
    "\n",
    "print(len(Files_Path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results_Dict = {}\n",
    "\n",
    "for file_path in Files_Path:\n",
    "    with open(file_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        results = []\n",
    "        for row in csv_reader:\n",
    "            results.append(row)\n",
    "        results = results[1:]\n",
    "        File_Name = file_path.split('.')[0].split('/')[2]\n",
    "#         print(File_Name)\n",
    "        \n",
    "        evaluation_results = [[],[],[],[]]\n",
    "        \n",
    "        for result in results:\n",
    "            measurement_name = int(result[0])\n",
    "            measurement_1 = round(float(result[1].split('$')[0]),4)\n",
    "            measurement_2 = round(float(result[2].split('$')[0]),4)\n",
    "            measurement_4 = round(float(result[3].split('$')[0]),4)\n",
    "            measurement_8 = round(float(result[4].split('$')[0]),4)\n",
    "            measurement_base = round(float(result[5].split('$')[0]),4)\n",
    "            \n",
    "            if measurement_name in Similarity_Measurements:\n",
    "#               Score 4\n",
    "                if measurement_1 < measurement_2 < measurement_4 < measurement_8 < measurement_base:\n",
    "#                     print(\"File Name: \" + File_Name)\n",
    "#                     print(\"Measurement Name: \" + str(measurement_name))\n",
    "#                     print(str(measurement_1) + \" < \" + str(measurement_2) + \" < \" + str(measurement_4) + \" < \" + str(measurement_8)\n",
    "#                           + \" < \" + str(measurement_base))\n",
    "                    evaluation_results[3].append(measurement_name)\n",
    "                    \n",
    "#               Score 3\n",
    "                elif measurement_1 < measurement_2 < measurement_4 < measurement_8:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                elif measurement_1 < measurement_2 < measurement_4 < measurement_base:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                elif measurement_1 < measurement_2 < measurement_8 < measurement_base:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                elif measurement_1 < measurement_4 < measurement_8 < measurement_base:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                elif measurement_2 < measurement_4 < measurement_8 < measurement_base:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                    \n",
    "#               Score 2\n",
    "                elif measurement_1 < measurement_2 < measurement_4:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 < measurement_2 < measurement_8:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 < measurement_2 < measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 < measurement_4 < measurement_8:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 < measurement_4 < measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 < measurement_8 < measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_2 < measurement_4 < measurement_8:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_2 < measurement_4 < measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_2 < measurement_8 < measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_4 < measurement_8 < measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                    \n",
    "#               Score 1\n",
    "                else:\n",
    "                    evaluation_results[0].append(measurement_name)\n",
    "            \n",
    "            if measurement_name in Distance_Measurements:\n",
    "#               Score 4\n",
    "                if measurement_1 > measurement_2 > measurement_4 > measurement_8 > measurement_base:\n",
    "                    evaluation_results[3].append(measurement_name)\n",
    "                    \n",
    "#               Score 3\n",
    "                elif measurement_1 > measurement_2 > measurement_4 > measurement_8:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                elif measurement_1 > measurement_2 > measurement_4 > measurement_base:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                elif measurement_1 > measurement_2 > measurement_8 > measurement_base:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                elif measurement_1 > measurement_4 > measurement_8 > measurement_base:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                elif measurement_2 > measurement_4 > measurement_8 > measurement_base:\n",
    "                    evaluation_results[2].append(measurement_name)\n",
    "                    \n",
    "#               Score 2\n",
    "                elif measurement_1 > measurement_2 > measurement_4:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 > measurement_2 > measurement_8:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 > measurement_2 > measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 > measurement_4 > measurement_8:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 > measurement_4 > measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_1 > measurement_8 > measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_2 > measurement_4 > measurement_8:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_2 > measurement_4 > measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_2 > measurement_8 > measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                elif measurement_4 > measurement_8 > measurement_base:\n",
    "                    evaluation_results[1].append(measurement_name)\n",
    "                    \n",
    "#               Score 1\n",
    "                else:\n",
    "                    evaluation_results[0].append(measurement_name)\n",
    "            \n",
    "        Results_Dict[File_Name] = evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('evaluation_3.csv', mode='w', newline=\"\") as csv_file:\n",
    "    evaluation_writer = csv.writer(csv_file, delimiter=',')\n",
    "    evaluation_writer.writerow(['Dataset', '# Measurements Score 5', '# Measurements Score 4','# Measurements Score 3','# Measurements Score 2'])\n",
    "\n",
    "    for key in Results_Dict:\n",
    "        expect_num_5 = len(Results_Dict[key][3])\n",
    "        print(key + \" with 5/5 in expect num: \" + str(expect_num))\n",
    "        expect_num_4 = len(Results_Dict[key][2])\n",
    "        print(key + \" with 4/5 in expect num: \" + str(expect_num))\n",
    "        expect_num_3 = len(Results_Dict[key][1])\n",
    "        print(key + \" with 3/5 in expect num: \" + str(expect_num))\n",
    "        expect_num_2 = len(Results_Dict[key][0])\n",
    "        print(key + \" with 2/5 in expect num: \" + str(expect_num))\n",
    "    \n",
    "        print(\"----\")\n",
    "        evaluation_writer.writerow([key, expect_num_5, expect_num_4, expect_num_3, expect_num_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Results_Dict['Reverse_Chess_Distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "similarity_measurement_dict = {}\n",
    "distance_measurement_dict = {}\n",
    "\n",
    "for measurement in Similarity_Measurements:\n",
    "    similarity_measurement_dict[measurement] = 0\n",
    "    \n",
    "    for key in Results_Dict:\n",
    "        result = []\n",
    "        result.extend(Results_Dict[key][2])\n",
    "        result.extend(Results_Dict[key][3])\n",
    "        \n",
    "        if measurement in result:\n",
    "            similarity_measurement_dict[measurement] += 1\n",
    "            \n",
    "for measurement in Distance_Measurements:\n",
    "    distance_measurement_dict[measurement] = 0\n",
    "    \n",
    "    for key in Results_Dict:\n",
    "        result = []\n",
    "        \n",
    "        result.extend(Results_Dict[key][3])\n",
    "#         result.extend(Results_Dict[key][2])\n",
    "#         result.extend(Results_Dict[key][1])\n",
    "#         result.extend(Results_Dict[key][0])\n",
    "        \n",
    "        if measurement in result:\n",
    "            distance_measurement_dict[measurement] += 1\n",
    "\n",
    "# print(\"Similarity\")\n",
    "# for key in similarity_measurement_dict:\n",
    "#     print(str(key) + \" Support Num: \" + str(similarity_measurement_dict[key]))\n",
    "\n",
    "print(\"Distance\")\n",
    "for key in distance_measurement_dict:\n",
    "    print(str(key) + \" Support Num: \" + str(distance_measurement_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "similarity_measurement_dict = {}\n",
    "distance_measurement_dict = {}\n",
    "\n",
    "for measurement in Similarity_Measurements:\n",
    "    similarity_measurement_dict[measurement] = 0\n",
    "    \n",
    "    for key in Results_Dict:\n",
    "        \n",
    "        if measurement in Results_Dict[key][3]:\n",
    "            similarity_measurement_dict[measurement] += 5\n",
    "        elif measurement in Results_Dict[key][2]:\n",
    "            similarity_measurement_dict[measurement] += 4\n",
    "        elif measurement in Results_Dict[key][1]:\n",
    "            similarity_measurement_dict[measurement] += 3\n",
    "        elif measurement in Results_Dict[key][0]:\n",
    "            similarity_measurement_dict[measurement] += 2\n",
    "            \n",
    "for measurement in Distance_Measurements:\n",
    "    distance_measurement_dict[measurement] = 0\n",
    "    \n",
    "    for key in Results_Dict:\n",
    "        if measurement in Results_Dict[key][3]:\n",
    "            distance_measurement_dict[measurement] += 5\n",
    "        elif measurement in Results_Dict[key][2]:\n",
    "            distance_measurement_dict[measurement] += 4\n",
    "        elif measurement in Results_Dict[key][1]:\n",
    "            distance_measurement_dict[measurement] += 3\n",
    "        elif measurement in Results_Dict[key][0]:\n",
    "            distance_measurement_dict[measurement] += 2\n",
    "\n",
    "print(\"Similarity\")\n",
    "for key in similarity_measurement_dict:\n",
    "    print(str(key) + \" Score: \" + str(similarity_measurement_dict[key]))\n",
    "\n",
    "print(\"Distance\")\n",
    "for key in distance_measurement_dict:\n",
    "    print(str(key) + \" Score: \" + str(distance_measurement_dict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluation Step - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "Files_Path = [\n",
    "    'MTV_Evaluation/Version_3/Reverse_Adult_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Bank_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Cardio_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Chess_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Credit_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Diamonds_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_Gamma_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Reverse_PokerPart_Distance.csv',\n",
    "    \n",
    "    'MTV_Evaluation/Version_3/Feature_0_Adult_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Bank_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Cardio_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Chess_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Credit_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Diamonds_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_Gamma_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_0_PokerPart_Distance.csv',\n",
    "    \n",
    "    'MTV_Evaluation/Version_3/Feature_1_Adult_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Bank_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Cardio_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Chess_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Credit_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Diamonds_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_Gamma_Distance.csv',\n",
    "    'MTV_Evaluation/Version_3/Feature_1_PokerPart_Distance.csv',\n",
    "]\n",
    "\n",
    "print(len(Files_Path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Results_Dict = {}\n",
    "\n",
    "for file_path in Files_Path:\n",
    "    with open(file_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        results = []\n",
    "        for row in csv_reader:\n",
    "            results.append(row)\n",
    "        results = results[1:]\n",
    "        File_Name = file_path.split('.')[0].split('/')[2]\n",
    "#         print(File_Name)\n",
    "        \n",
    "        for result in results:\n",
    "            measurement_name = int(result[0])\n",
    "            if measurement_name == 30:\n",
    "                measurement_1 = round(float(result[1].split('$')[0]),4)\n",
    "                measurement_2 = round(float(result[2].split('$')[0]),4)\n",
    "                measurement_4 = round(float(result[3].split('$')[0]),4)\n",
    "                measurement_8 = round(float(result[4].split('$')[0]),4)\n",
    "                measurement_base = round(float(result[5].split('$')[0]),4)\n",
    "                \n",
    "                if measurement_1 > measurement_2 > measurement_4 > measurement_8 > measurement_base:\n",
    "                    score = 5\n",
    "                    \n",
    "                elif measurement_1 > measurement_2 > measurement_4 > measurement_8:\n",
    "                    score = 4\n",
    "                elif measurement_1 > measurement_2 > measurement_4 > measurement_base:\n",
    "                    score = 4\n",
    "                elif measurement_1 > measurement_2 > measurement_8 > measurement_base:\n",
    "                    score = 4\n",
    "                elif measurement_1 > measurement_4 > measurement_8 > measurement_base:\n",
    "                    score = 4\n",
    "                elif measurement_2 > measurement_4 > measurement_8 > measurement_base:\n",
    "                    score = 4\n",
    "                    \n",
    "                elif measurement_1 > measurement_2 > measurement_4:\n",
    "                    score = 3\n",
    "                elif measurement_1 > measurement_2 > measurement_8:\n",
    "                    score = 3\n",
    "                elif measurement_1 > measurement_2 > measurement_base:\n",
    "                    score = 3\n",
    "                elif measurement_1 > measurement_4 > measurement_8:\n",
    "                    score = 3\n",
    "                elif measurement_1 > measurement_4 > measurement_base:\n",
    "                    score = 3\n",
    "                elif measurement_1 > measurement_8 > measurement_base:\n",
    "                    score = 3\n",
    "                elif measurement_2 > measurement_4 > measurement_8:\n",
    "                    score = 3\n",
    "                elif measurement_2 > measurement_4 > measurement_base:\n",
    "                    score = 3\n",
    "                elif measurement_2 > measurement_8 > measurement_base:\n",
    "                    score = 3\n",
    "                elif measurement_4 > measurement_8 > measurement_base:\n",
    "                    score = 3\n",
    "                    \n",
    "                else:\n",
    "                    score = 2\n",
    "                \n",
    "                if score == 4:\n",
    "                    print(File_Name)\n",
    "                \n",
    "                Results_Dict[File_Name] = [result[1], result[2], result[3], result[4], result[5], score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluation - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from MySkmultiflow.data import DataStream\n",
    "from MySkmultiflow.trees import HoeffdingTreeClassifier\n",
    "from statistics import mean, stdev\n",
    "import MTVlib\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Iteration = 30\n",
    "Accuracy_base_all = []\n",
    "Accuracy_1_1_all = []\n",
    "Accuracy_1_2_all = []\n",
    "Accuracy_1_4_all = []\n",
    "Accuracy_1_8_all = []\n",
    "\n",
    "for i in range(Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    dataframe = pd.read_csv('MTV_Datasets/Preprocessed_Datasets/Synthetic_Adult_Transformed.csv', header=None)\n",
    "    dataframe.columns = dataframe.columns.astype(str)\n",
    "    target_index = '59'\n",
    "    count = len(dataframe[target_index])\n",
    "    \n",
    "    dataframe_base, dataframe_1_1, dataframe_1_2, dataframe_1_4, dataframe_1_8 = MTVlib.generate_dataframe_reverse(dataframe, target_index, i)\n",
    "    \n",
    "    target_idx = 59\n",
    "    cat_features= list(range(target_idx))\n",
    "    \n",
    "    Stream_Base = DataStream(dataframe_base, target_idx=target_idx, cat_features=cat_features)\n",
    "    Stream_1_1 = DataStream(dataframe_1_1, target_idx=target_idx, cat_features=cat_features)\n",
    "    Stream_1_2 = DataStream(dataframe_1_2, target_idx=target_idx, cat_features=cat_features)\n",
    "    Stream_1_4 = DataStream(dataframe_1_4, target_idx=target_idx, cat_features=cat_features)\n",
    "    Stream_1_8 = DataStream(dataframe_1_8, target_idx=target_idx, cat_features=cat_features)\n",
    "\n",
    "    HT_Base = HoeffdingTreeClassifier(binary_split=True, no_preprune=True)\n",
    "    HT_Base.partial_fit(Stream_Base.X, Stream_Base.y)\n",
    "\n",
    "    correct_base = 0\n",
    "    correct_1_1 = 0\n",
    "    correct_1_2 = 0\n",
    "    correct_1_4 = 0\n",
    "    correct_1_8 = 0\n",
    "\n",
    "    count = len(dataframe[target_index])\n",
    "    X_base, Y_base = Stream_Base.next_sample(count)\n",
    "    X_1_1, Y_1_1 = Stream_1_1.next_sample(count)\n",
    "    X_1_2, Y_1_2 = Stream_1_2.next_sample(count)\n",
    "    X_1_4, Y_1_4 = Stream_1_4.next_sample(count)\n",
    "    X_1_8, Y_1_8 = Stream_1_8.next_sample(count)\n",
    "\n",
    "    pred_base = HT_Base.predict(X_base)\n",
    "    pred_1_1 = HT_Base.predict(X_1_1)\n",
    "    pred_1_2 = HT_Base.predict(X_1_2)\n",
    "    pred_1_4 = HT_Base.predict(X_1_4)\n",
    "    pred_1_8 = HT_Base.predict(X_1_8)\n",
    "\n",
    "\n",
    "    for i in range(count):\n",
    "        if pred_base[i] == Y_base[i]:\n",
    "            correct_base += 1\n",
    "        if pred_1_1[i] == Y_1_1[i]:\n",
    "            correct_1_1 += 1\n",
    "        if pred_1_2[i] == Y_1_2[i]:\n",
    "            correct_1_2 += 1\n",
    "        if pred_1_4[i] == Y_1_4[i]:\n",
    "            correct_1_4 += 1\n",
    "        if pred_1_8[i] == Y_1_8[i]:\n",
    "            correct_1_8 += 1\n",
    "\n",
    "    Accuracy_base = correct_base / count\n",
    "    Accuracy_1_1 = correct_1_1 / count\n",
    "    Accuracy_1_2 = correct_1_2 / count\n",
    "    Accuracy_1_4 = correct_1_4 / count\n",
    "    Accuracy_1_8 = correct_1_8 / count\n",
    "    \n",
    "    Accuracy_base_all.append(Accuracy_base)\n",
    "    Accuracy_1_1_all.append(Accuracy_1_1)\n",
    "    Accuracy_1_2_all.append(Accuracy_1_2)\n",
    "    Accuracy_1_4_all.append(Accuracy_1_4)\n",
    "    Accuracy_1_8_all.append(Accuracy_1_8)\n",
    "\n",
    "print(Accuracy_base_all)\n",
    "print(Accuracy_1_1_all)\n",
    "print(Accuracy_1_2_all)\n",
    "print(Accuracy_1_4_all)\n",
    "print(Accuracy_1_8_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('MTV_Evaluation\\Evaluation_Accuracy.csv', 'a', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    \n",
    "    mean_base = mean(Accuracy_base_all)\n",
    "    mean_1 = mean(Accuracy_1_1_all)\n",
    "    mean_2 = mean(Accuracy_1_2_all)\n",
    "    mean_4 = mean(Accuracy_1_4_all)\n",
    "    mean_8 = mean(Accuracy_1_8_all)\n",
    "    \n",
    "    stdev_base = stdev(Accuracy_base_all)\n",
    "    stdev_1 = stdev(Accuracy_1_1_all)\n",
    "    stdev_2 = stdev(Accuracy_1_2_all)\n",
    "    stdev_4 = stdev(Accuracy_1_4_all)\n",
    "    stdev_8 = stdev(Accuracy_1_8_all)\n",
    "    \n",
    "    r_b = str(round(mean_base,4)) + \" $\\pm$ \" + str(round(stdev_base,4))\n",
    "    r_1 = str(round(mean_1,4)) + \" $\\pm$ \" + str(round(stdev_1,4))\n",
    "    r_2 = str(round(mean_2,4)) + \" $\\pm$ \" + str(round(stdev_2,4))\n",
    "    r_4 = str(round(mean_4,4)) + \" $\\pm$ \" + str(round(stdev_4,4))\n",
    "    r_8 = str(round(mean_8,4)) + \" $\\pm$ \" + str(round(stdev_8,4))\n",
    "    \n",
    "    dataset = \"Reverse_Adult\"\n",
    "    \n",
    "    writer.writerow([dataset, r_b, r_1, r_2, r_4, r_8])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluation - Wasserstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import MTVlib\n",
    "import math\n",
    "from scipy import stats\n",
    "from statistics import mean, stdev\n",
    "\n",
    "def Get_Wasserstein_Distance(DF_1, DF_2, Feature_Shift_List):\n",
    "#     print(\"Get Wasserstein Distance\")\n",
    "    features = DF_1.columns[:-1]\n",
    "#     print(features)\n",
    "    distances = []\n",
    "\n",
    "    for feature in features:  \n",
    "        df_1_values = DF_1[feature]\n",
    "        df_2_values = DF_2[feature]\n",
    "        distance = stats.wasserstein_distance(df_1_values, df_2_values)\n",
    "        distances.append(distance)\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Iteration = 2\n",
    "\n",
    "Base_Base_Distance_All = []\n",
    "Base_1_Distance_All = []\n",
    "Base_2_Distance_All = []\n",
    "Base_4_Distance_All = []\n",
    "Base_8_Distance_All = []\n",
    "\n",
    "for i in range(Iteration):\n",
    "    print(\"Currently Working on Iteration: \" + str(i+1))\n",
    "    \n",
    "    dataframe = pd.read_csv('MTV_Datasets/Preprocessed_Datasets/Synthetic_Adult_Transformed.csv', header=None)\n",
    "    dataframe.columns = dataframe.columns.astype(str)\n",
    "    target_index = '59'\n",
    "    count = len(dataframe[target_index])\n",
    "    drift_type = 0\n",
    "\n",
    "    feature_shift_list = ['24', '47', '26', '46', '56', '57', '35', '48', '33', '8', '36', '18', '0', '50']\n",
    "    \n",
    "    dataframe_base, dataframe_1_1, dataframe_1_2, dataframe_1_4, dataframe_1_8 = MTVlib.generate_dataframe_feature(dataframe, target_index, feature_shift_list, i, drift_type)\n",
    "\n",
    "    Base_Base_Distance = sum(Get_Wasserstein_Distance(dataframe_base, dataframe_base, feature_shift_list))\n",
    "    Base_1_1_Distance = sum(Get_Wasserstein_Distance(dataframe_base, dataframe_1_1, feature_shift_list))\n",
    "    Base_1_2_Distance = sum(Get_Wasserstein_Distance(dataframe_base, dataframe_1_2, feature_shift_list))\n",
    "    Base_1_4_Distance = sum(Get_Wasserstein_Distance(dataframe_base, dataframe_1_4, feature_shift_list))\n",
    "    Base_1_8_Distance = sum(Get_Wasserstein_Distance(dataframe_base, dataframe_1_8, feature_shift_list))\n",
    "    \n",
    "    Base_Base_Distance_All.append(Base_Base_Distance)\n",
    "    Base_1_Distance_All.append(Base_1_1_Distance)\n",
    "    Base_2_Distance_All.append(Base_1_2_Distance)\n",
    "    Base_4_Distance_All.append(Base_1_4_Distance)\n",
    "    Base_8_Distance_All.append(Base_1_8_Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('MTV_Evaluation\\Evaluation_Wasserstein_Distance.csv', 'a', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file, delimiter=',')\n",
    "    \n",
    "    mean_base = mean(Base_Base_Distance_All)\n",
    "    mean_1 = mean(Base_1_Distance_All)\n",
    "    mean_2 = mean(Base_2_Distance_All)\n",
    "    mean_4 = mean(Base_4_Distance_All)\n",
    "    mean_8 = mean(Base_8_Distance_All)\n",
    "    \n",
    "    stdev_base = stdev(Base_Base_Distance_All)\n",
    "    stdev_1 = stdev(Base_1_Distance_All)\n",
    "    stdev_2 = stdev(Base_2_Distance_All)\n",
    "    stdev_4 = stdev(Base_4_Distance_All)\n",
    "    stdev_8 = stdev(Base_8_Distance_All)\n",
    "    \n",
    "    r_b = str(round(mean_base,4)) + \" $\\pm$ \" + str(round(stdev_base,4))\n",
    "    r_1 = str(round(mean_1,4)) + \" $\\pm$ \" + str(round(stdev_1,4))\n",
    "    r_2 = str(round(mean_2,4)) + \" $\\pm$ \" + str(round(stdev_2,4))\n",
    "    r_4 = str(round(mean_4,4)) + \" $\\pm$ \" + str(round(stdev_4,4))\n",
    "    r_8 = str(round(mean_8,4)) + \" $\\pm$ \" + str(round(stdev_8,4))\n",
    "    \n",
    "    dataset = \"Feature_0_Adult\"\n",
    "    \n",
    "    writer.writerow([dataset, r_b, r_1, r_2, r_4, r_8])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Base_Base_Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluation - Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from MySkmultiflow.data import DataStream\n",
    "from MySkmultiflow.trees import HoeffdingTreeClassifier\n",
    "import csv\n",
    "import pandas as pd\n",
    "import eli5\n",
    "import MTVlib\n",
    "\n",
    "def Get_Permutation_Importance(Model,DataStream):\n",
    "    print(\"Get Permutation Importance\")\n",
    "    PermutationImportance = eli5.sklearn.PermutationImportance(Model,random_state=42).fit(DataStream.X, DataStream.y)\n",
    "    PermutationImportance_Means = PermutationImportance.feature_importances_\n",
    "    \n",
    "    return PermutationImportance_Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('MTV_Datasets/Preprocessed_Datasets/Synthetic_Adult_Transformed.csv', header=None)\n",
    "dataframe.columns = dataframe.columns.astype(str)\n",
    "target_index = '59'\n",
    "count = len(dataframe[target_index])\n",
    "    \n",
    "dataframe_base, dataframe_1_1, dataframe_1_2, dataframe_1_4, dataframe_1_8 = MTVlib.generate_dataframe_reverse(dataframe, target_index, 0)\n",
    "    \n",
    "target_idx = 59\n",
    "cat_features= list(range(target_idx))\n",
    "    \n",
    "Stream_Base = DataStream(dataframe_base, target_idx=target_idx, cat_features=cat_features)\n",
    "Stream_1_1 = DataStream(dataframe_1_1, target_idx=target_idx, cat_features=cat_features)\n",
    "Stream_1_2 = DataStream(dataframe_1_2, target_idx=target_idx, cat_features=cat_features)\n",
    "Stream_1_4 = DataStream(dataframe_1_4, target_idx=target_idx, cat_features=cat_features)\n",
    "Stream_1_8 = DataStream(dataframe_1_8, target_idx=target_idx, cat_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "HT_Base = HoeffdingTreeClassifier(binary_split=True, no_preprune=True)\n",
    "HT_Base.partial_fit(Stream_Base.X, Stream_Base.y)\n",
    "\n",
    "constrain_dict = HT_Base.constrain_dict\n",
    "Base_feature_list = HT_Base.feature_list.copy()\n",
    "\n",
    "HT_1_1 = HoeffdingTreeClassifier(constrain_dict=constrain_dict, feature_list=Base_feature_list)\n",
    "HT_1_1.partial_fit(Stream_1_1.X, Stream_1_1.y)\n",
    "feature_list_base_1 = HT_1_1.feature_list\n",
    "\n",
    "Base_feature_list = HT_Base.feature_list.copy()\n",
    "HT_1_2 = HoeffdingTreeClassifier(constrain_dict=constrain_dict, feature_list=Base_feature_list)\n",
    "HT_1_2.partial_fit(Stream_1_2.X, Stream_1_2.y)\n",
    "\n",
    "Base_feature_list = HT_Base.feature_list.copy()\n",
    "HT_1_4 = HoeffdingTreeClassifier(constrain_dict=constrain_dict, feature_list=Base_feature_list)\n",
    "HT_1_4.partial_fit(Stream_1_4.X, Stream_1_4.y)\n",
    "\n",
    "Base_feature_list = HT_Base.feature_list.copy()\n",
    "HT_1_8 = HoeffdingTreeClassifier(constrain_dict=constrain_dict, feature_list=Base_feature_list)\n",
    "HT_1_8.partial_fit(Stream_1_8.X, Stream_1_8.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Permutation_Importance_Base = Get_Permutation_Importance(HT_Base, Stream_Base)\n",
    "Permutation_Importance_1_1 = Get_Permutation_Importance(HT_1_1, Stream_1_1)\n",
    "Permutation_Importance_1_2 = Get_Permutation_Importance(HT_1_2, Stream_1_2)\n",
    "Permutation_Importance_1_4 = Get_Permutation_Importance(HT_1_4, Stream_1_4)\n",
    "Permutation_Importance_1_8 = Get_Permutation_Importance(HT_1_8, Stream_1_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluation Step - 3 - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reverse_Adult: 5\n",
      "Reverse_Bank: 5\n",
      "Reverse_Cardio: 5\n",
      "Reverse_Chess: 5\n",
      "Reverse_Credit: 5\n",
      "Reverse_Diamonds: 5\n",
      "Reverse_Gamma: 5\n",
      "Reverse_PokerPart: 5\n",
      "Feature_0_Adult: 2\n",
      "Feature_0_Bank: 5\n",
      "Feature_0_Cardio: 5\n",
      "Feature_0_Chess: 5\n",
      "Feature_0_Credit: 2\n",
      "Feature_0_Diamonds: 5\n",
      "Feature_0_Gamma: 5\n",
      "Feature_0_PokerPart: 2\n",
      "Feature_1_Adult: 5\n",
      "Feature_1_Bank: 2\n",
      "Feature_1_Cardio: 2\n",
      "Feature_1_Chess: 5\n",
      "Feature_1_Credit: 2\n",
      "Feature_1_Diamonds: 5\n",
      "Feature_1_Gamma: 5\n",
      "Feature_1_PokerPart: 5\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = \"MTV_Evaluation/Evaluation_Accuracy.csv\"\n",
    "with open(file_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        results = []\n",
    "        for row in csv_reader:\n",
    "            results.append(row)\n",
    "        \n",
    "        for result in results:\n",
    "            dataset_name = result[0]\n",
    "#             print(result)\n",
    "            measurement_1 = round(float(result[1].split('$')[0]),4)\n",
    "            measurement_2 = round(float(result[2].split('$')[0]),4)\n",
    "            measurement_4 = round(float(result[3].split('$')[0]),4)\n",
    "            measurement_8 = round(float(result[4].split('$')[0]),4)\n",
    "            measurement_base = round(float(result[5].split('$')[0]),4)\n",
    "            \n",
    "#             print(measurement_1)\n",
    "#             print(measurement_2)\n",
    "#             print(measurement_4)\n",
    "            \n",
    "            if measurement_1 < measurement_2 < measurement_4 < measurement_8 < measurement_base:\n",
    "                score = 5\n",
    "                    \n",
    "            elif measurement_1 < measurement_2 < measurement_4 < measurement_8:\n",
    "                    score = 4\n",
    "            elif measurement_1 < measurement_2 < measurement_4 < measurement_base:\n",
    "                    score = 4\n",
    "            elif measurement_1 < measurement_2 < measurement_8 < measurement_base:\n",
    "                    score = 4\n",
    "            elif measurement_1 < measurement_4 < measurement_8 < measurement_base:\n",
    "                    score = 4\n",
    "            elif measurement_2 < measurement_4 < measurement_8 < measurement_base:\n",
    "                    score = 4\n",
    "                    \n",
    "            elif measurement_1 < measurement_2 < measurement_4:\n",
    "                score = 3\n",
    "            elif measurement_1 < measurement_2 < measurement_8:\n",
    "                score = 3\n",
    "            elif measurement_1 < measurement_2 < measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_1 < measurement_4 < measurement_8:\n",
    "                score = 3\n",
    "            elif measurement_1 < measurement_4 < measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_1 < measurement_8 < measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_2 < measurement_4 < measurement_8:\n",
    "                score = 3\n",
    "            elif measurement_2 < measurement_4 < measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_2 < measurement_8 < measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_4 < measurement_8 < measurement_base:\n",
    "                score = 3\n",
    "                    \n",
    "            else:\n",
    "                score = 2\n",
    "            \n",
    "            print(dataset_name + \": \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Step - 3 - Wasserstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_0_Adult: 5\n",
      "Feature_0_Bank: 5\n",
      "Feature_0_Cardio: 5\n",
      "Feature_0_Chess: 5\n",
      "Feature_0_Credit: 5\n",
      "Feature_0_Diamonds: 5\n",
      "Feature_0_Gamma: 5\n",
      "Feature_0_PokerPart: 5\n",
      "Feature_1_Adult: 5\n",
      "Feature_1_Bank: 5\n",
      "Feature_1_Cardio: 5\n",
      "Feature_1_Chess: 5\n",
      "Feature_1_Credit: 5\n",
      "Feature_1_Diamonds: 5\n",
      "Feature_1_Gamma: 5\n",
      "Feature_1_PokerPart: 5\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "file_path = \"MTV_Evaluation/Evaluation_Wasserstein_Distance.csv\"\n",
    "with open(file_path) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        results = []\n",
    "        for row in csv_reader:\n",
    "            results.append(row)\n",
    "        \n",
    "        for result in results:\n",
    "            dataset_name = result[0]\n",
    "#             print(result)\n",
    "            measurement_1 = round(float(result[1].split('$')[0]),4)\n",
    "            measurement_2 = round(float(result[2].split('$')[0]),4)\n",
    "            measurement_4 = round(float(result[3].split('$')[0]),4)\n",
    "            measurement_8 = round(float(result[4].split('$')[0]),4)\n",
    "            measurement_base = round(float(result[5].split('$')[0]),4)\n",
    "            \n",
    "#             print(measurement_1)\n",
    "#             print(measurement_2)\n",
    "#             print(measurement_4)\n",
    "            \n",
    "            if measurement_1 > measurement_2 > measurement_4 > measurement_8 > measurement_base:\n",
    "                score = 5\n",
    "                    \n",
    "            elif measurement_1 > measurement_2 > measurement_4 > measurement_8:\n",
    "                    score = 4\n",
    "            elif measurement_1 > measurement_2 > measurement_4 > measurement_base:\n",
    "                    score = 4\n",
    "            elif measurement_1 > measurement_2 > measurement_8 > measurement_base:\n",
    "                    score = 4\n",
    "            elif measurement_1 > measurement_4 > measurement_8 > measurement_base:\n",
    "                    score = 4\n",
    "            elif measurement_2 > measurement_4 > measurement_8 > measurement_base:\n",
    "                    score = 4\n",
    "                    \n",
    "            elif measurement_1 > measurement_2 > measurement_4:\n",
    "                score = 3\n",
    "            elif measurement_1 > measurement_2 > measurement_8:\n",
    "                score = 3\n",
    "            elif measurement_1 > measurement_2 > measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_1 > measurement_4 > measurement_8:\n",
    "                score = 3\n",
    "            elif measurement_1 > measurement_4 > measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_1 > measurement_8 > measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_2 > measurement_4 > measurement_8:\n",
    "                score = 3\n",
    "            elif measurement_2 > measurement_4 > measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_2 > measurement_8 > measurement_base:\n",
    "                score = 3\n",
    "            elif measurement_4 > measurement_8 > measurement_base:\n",
    "                score = 3\n",
    "                    \n",
    "            else:\n",
    "                score = 2\n",
    "            \n",
    "            print(dataset_name + \": \" + str(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
